apiVersion: batch/v1
kind: Job
metadata:
  generateName: vllm-server-client-
  labels:
    kueue.x-k8s.io/queue-name:  eidf230ns-user-queue
spec:
  completions: 1
  backoffLimit: 0
  ttlSecondsAfterFinished: 1800
  template:
    metadata:
      name: job-vllm-server-client
    spec:
      containers:
      - name: vllm-server
        image: vllm/vllm-openai:latest
        imagePullPolicy: IfNotPresent
        command: ["vllm"]
        args: 
          - "serve"
          - "openai/gpt-oss-20b"
          - "--tensor-parallel-size"
          - "2"
          - "--max-num-seqs"
          - "4"
          - "--disable-log-requests"
          - "--async-scheduling"
          - "--no-enable-prefix-caching"
          - "--gpu-memory-utilization"
          - "0.95"
          - "--max-num-batched-tokens"
          - "8192"
          - "--max-model-len"
          - "10240"
          - "--port"
          - "8888"
        ports:
          - containerPort: 8888
        resources:
          requests:
            cpu: 64
            memory: '512Gi'
          limits:
            cpu: 64
            memory: '512Gi'
            nvidia.com/gpu: 2
      - name: bench-serving
        image: python:3.10-slim 
        imagePullPolicy: IfNotPresent
        command: ["/bin/bash", "-c"]
        args:
            - |
              apt-get update
              apt-get install git
              git clone git@github.com:markxio/bench_serving.git
              cd bench_serving
              pip install -r requirements.txt
              python health.py &> health.log
              bash bench.sh &> perf.log
        resources:
          requests:
            cpu: 1
            memory: '4Gi'
          limits:
            cpu: 1
            memory: '4Gi'
        volumeMounts:
          - mountPath: /mnt/ceph
            name: volume
      restartPolicy: Never
      volumes:
        - name: volume
          persistentVolumeClaim:
            claimName: client-ceph-pvc
      nodeSelector:
        nvidia.com/gpu.product: NVIDIA-H100-80GB-HBM3
        #nvidia.com/gpu.product: NVIDIA-A100-SXM4-40GB-MIG-1g.5gb
