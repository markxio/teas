apiVersion: batch/v1
kind: Job
metadata:
  generateName: vllm-server-client-
  labels:
    kueue.x-k8s.io/queue-name:  eidf230ns-user-queue
spec:
  completions: 1
  backoffLimit: 0
  ttlSecondsAfterFinished: 1800
  template:
    metadata:
      name: job-vllm-server-client
    spec:
      containers:
      - name: vllm-server
        image: vllm/vllm-openai:latest
        imagePullPolicy: IfNotPresent
        command: ["vllm"]
        args: 
          - "serve"
          - "openai/gpt-oss-20b"
          - "--tensor-parallel-size"
          - "2"
          - "--max-num-seqs"
          - "4"
          - "--disable-log-requests"
          - "--async-scheduling"
          - "--no-enable-prefix-caching"
          - "--gpu-memory-utilization"
          - "0.95"
          - "--max-num-batched-tokens"
          - "8192"
          - "--max-model-len"
          - "10240"
          - "--port"
          - "8888"
        ports:
          - containerPort: 8888
        resources:
          requests:
            cpu: 64
            memory: '512Gi'
          limits:
            cpu: 64
            memory: '512Gi'
            nvidia.com/gpu: 2
      - name: http-client
        image: python:3.10-slim 
        imagePullPolicy: IfNotPresent
        command: ["/bin/bash", "-c"]
        args:
            - |
              pip install requests;
              echo "Waiting for vllm server..."; sleep 300;
              python - <<'EOF'
              import requests, json, time
              url = "http://localhost:8888/v1/completions"
              data = {
                "model": "openai/gpt-oss-20b",
                "prompt": "Create a job in Kubernetes",
                "max_tokens": 50
              }
              print("Sending request to vllm server...")
              r = requests.post(url, json=data)
              print("Response:", r.text)
              with open("/mnt/ceph/server_response.txt", "a") as f:
                f.write(r.text)
              EOF
              echo "Client finished."
        resources:
          requests:
            cpu: 1
            memory: '4Gi'
          limits:
            cpu: 1
            memory: '4Gi'
        volumeMounts:
          - mountPath: /mnt/ceph
            name: volume
      restartPolicy: Never
      volumes:
        - name: volume
          persistentVolumeClaim:
            claimName: client-ceph-pvc
      nodeSelector:
        nvidia.com/gpu.product: NVIDIA-H100-80GB-HBM3
        #nvidia.com/gpu.product: NVIDIA-A100-SXM4-40GB-MIG-1g.5gb
